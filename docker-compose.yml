services:
  crawler:
    build:
      context: .
      dockerfile: backend/Dockerfile.crawler
    container_name: globe_media_crawler
    restart: always # Auto-restart strategy
    volumes:
      - ./data/crawler_persistence:/app/crawlers_jobdir # Persistence mapping
      - ./data/logs:/app/logs # Log mapping
      - ./data/output:/app/data # Data output mapping
    environment:
      - MEDIA_CLOUD_API_KEY=${MEDIA_CLOUD_API_KEY}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    healthcheck:
      test: ["CMD-SHELL", "pgrep -f scrapy || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Optional: PostgreSQL service for local testing
  # db:
  #   image: postgres:15
  #   volumes:
  #     - postgres_data:/var/lib/postgresql/data
  #   environment:
  #     POSTGRES_USER: user
  #     POSTGRES_PASSWORD: password
  #     POSTGRES_DB: globemediapulse

# volumes:
#   postgres_data:
